{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f522cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"dataset_website.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f030b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d416780",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df,size=10):\n",
    "    \n",
    "    corr=df.corr()\n",
    "    fig,ax=plt.subplots(figsize=(size,size))\n",
    "    ax.legend()\n",
    "    cax=ax.matshow(corr)\n",
    "    fig.colorbar(cax)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation='vertical')\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    \n",
    "\n",
    "plot_corr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.color_palette('muted'):\n",
    "    sns.countplot(x=data['Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab122c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,1:31].values\n",
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating holders to store the model performance results\n",
    "ML_Model2 = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "#function to call for storing the results\n",
    "def storeResults(model, a,b):\n",
    "  ML_Model2.append(model)\n",
    "  acc_train.append(round(a, 3))\n",
    "  acc_test.append(round(b, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test|\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf904a",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60450da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression() \n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=lr.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test_lr = lr.predict(x_test)\n",
    "y_train_lr = lr.predict(x_train)\n",
    "acc_train_lr = accuracy_score(y_train,y_train_lr)*100\n",
    "acc_test_lr = accuracy_score(y_test,y_test_lr)*100\n",
    "storeResults('Logistic Regression', acc_train_lr, acc_test_lr)\n",
    "log_reg=accuracy_score (y_test,y_pred1)\n",
    "log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45ff45",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_forest = forest.predict(x_test)\n",
    "y_train_forest = forest.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_forest = accuracy_score(y_train,y_train_forest)*100\n",
    "acc_test_forest = accuracy_score(y_test,y_test_forest)*100\n",
    "storeResults('Random Forest', acc_train_forest, acc_test_forest)\n",
    "print(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\n",
    "print(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a574c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({ 'ML Model': ML_Model2,    \n",
    "    'Train Accuracy': acc_train,\n",
    "    'Test Accuracy': acc_test})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef01f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(ML_Model2,acc_test,width=0.3,color=['violet','red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05ae86",
   "metadata": {},
   "source": [
    "#### Based on different Algorithms we choose Random forest because it gives better accuracy compared to other Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eed5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4620d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(forest,open('Phishing_Website.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
